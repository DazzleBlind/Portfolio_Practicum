{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkSyAelqOiba"
      },
      "source": [
        "# Обучение модели классификации комментариев  \n",
        "\n",
        "###Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "#### Нужно обучить модель классифицировать комментарии на позитивные и негативные.\n",
        "\n",
        "Требование: метрика качества F1 должна быть не меньше 0.75 .\n",
        "\n",
        "В нашем распоряжении данные из файла: `toxic_comments.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZFFmU4PPQkS"
      },
      "source": [
        "## Загрузка библеотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu_VhHW7OyRw",
        "outputId": "9006d0ff-2bd1-4ed2-d98f-de67dded33d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Для работы с данными:\n",
        "# Импортируем pandas как pd:\n",
        "import pandas as pd\n",
        "# Импортируемnumpy как np:\n",
        "import numpy as np\n",
        "# Для упрощения работы используется кастомизированный класс Dataset:\n",
        "from torch.utils.data import Dataset\n",
        "# Импорт метода для создания выборок:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Импорт модели Fasttext:\n",
        "from gensim.models import FastText\n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "# Импортируем токинайзер и модель(Bert):\n",
        "import sklearn\n",
        "import torch\n",
        "!pip install transformers sentencepiece\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Импорт \"хэлперов\":\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "## Для оценки:\n",
        "import math\n",
        "# Импорт метрики:\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Библиотеки для подготовки текста:\n",
        "import re\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Для загрузки файлов(у меня):\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SgH5KEdX42O"
      },
      "source": [
        "## Загрузка данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f6DcQn-X491"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df = pd.read_csv('/datasets/toxic_comments.csv', index_col=[0], parse_dates=[0])\n",
        "except:\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/For_data/toxic_comments.csv\", index_col=[0], parse_dates=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgsVVhF_YHyl"
      },
      "outputs": [],
      "source": [
        "df.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09LeaOZVYbZO"
      },
      "outputs": [],
      "source": [
        "# Создание функции для изучения данных:\n",
        "def information(data):\n",
        "    print('Общая информация о таблице:')\n",
        "    print(data.info(), '\\n')\n",
        "    print('Индекс монотонный? - ',data.index.is_monotonic)\n",
        "    print('\\n')\n",
        "    print('Размер таблицы равен:', data.shape, '\\n')\n",
        "    print('Кол-во пропусков:', data.isna().sum(), '\\n')\n",
        "    print('Кол-во явных дубликатов:', data.duplicated().sum(), '\\n')\n",
        "    display(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "7I3HYcmFYrCl",
        "outputId": "c059fd95-61e6-4b29-8f60-120c986313ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Общая информация о таблице:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 159292 entries, 0 to 159450\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159292 non-null  object\n",
            " 1   toxic   159292 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.6+ MB\n",
            "None \n",
            "\n",
            "Индекс монотонный? -  True\n",
            "\n",
            "\n",
            "Размер таблицы равен: (159292, 2) \n",
            "\n",
            "Кол-во пропусков: text     0\n",
            "toxic    0\n",
            "dtype: int64 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-b3ed42aba740>:5: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n",
            "  print('Индекс монотонный? - ',data.index.is_monotonic)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Кол-во явных дубликатов: 0 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-17656ea8-2bfe-4de8-adf9-3644b3f741be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17656ea8-2bfe-4de8-adf9-3644b3f741be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17656ea8-2bfe-4de8-adf9-3644b3f741be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17656ea8-2bfe-4de8-adf9-3644b3f741be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74e228e0-6dcd-439c-9d7d-d6ea39197e21\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74e228e0-6dcd-439c-9d7d-d6ea39197e21')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74e228e0-6dcd-439c-9d7d-d6ea39197e21 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Изучение информации о таблице:\n",
        "information(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rQRnvK8o-FF"
      },
      "source": [
        "### Вывод:\n",
        "У нас есть таблица размером 159292 строк.\n",
        "\n",
        "Целевой признак находится в столбце toxic.\n",
        "\n",
        "Явных дубликатов, как и пропусков нет.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frKVkyts6yy_"
      },
      "source": [
        "# Fasttext:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPd6hL5YppkX"
      },
      "source": [
        "## Подготовка данных:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-_m7fK06hXq"
      },
      "source": [
        "#### Предварительная обработка текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDFkhX2O0B-o"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\sa-zA-Z0-9@\\[\\]]',' ',text) # Удаляет пунктцацию\n",
        "    text = re.sub(r'\\w*\\d+\\w*', '', text) # Удаляет цифры\n",
        "    text = re.sub('\\s{2,}', \" \", text) # Удаляет ненужные пробелы\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MjajVw30GWV"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwzX33pK2GG7"
      },
      "source": [
        "Разбитие данных на выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1b51wwXw-Fa"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df,\n",
        "                                   shuffle=False, test_size=0.2,train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7tMtlAI0NJ_"
      },
      "outputs": [],
      "source": [
        "with open('train.txt', 'w') as f:\n",
        "    for each_text, each_label in zip(train['text'], train['toxic']):\n",
        "        f.writelines(f'__label__{each_label} {each_text}\\n')\n",
        "\n",
        "with open('test.txt', 'w') as f:\n",
        "    for each_text, each_label in zip(test['text'], test['toxic']):\n",
        "        f.writelines(f'__label__{each_label} {each_text}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJi7hQE62Tl"
      },
      "source": [
        "## Работа с моделью:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBz1vabq04VE"
      },
      "outputs": [],
      "source": [
        "# Обучение модели\n",
        "model6 = fasttext.train_supervised('train.txt',\n",
        "                                   autotuneValidationFile='test.txt',\n",
        "                                   autotuneMetric=\"f1:__label__1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTTnVv4S08OM",
        "outputId": "ff65265d-7d89-477b-abb8-2e2167b9506e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_size=31859\n",
            "precision=0.95885\n",
            "recall=0.95885\n",
            "F1=0.95885\n"
          ]
        }
      ],
      "source": [
        "# Создадим функцую для отображения результатов обучения модели\n",
        "def print_results(sample_size, precision, recall):\n",
        "    precision   = round(precision, 6)\n",
        "    recall      = round(recall, 6)\n",
        "    F1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    print(f'{sample_size=}')\n",
        "    print(f'{precision=}')\n",
        "    print(f'{recall=}')\n",
        "    print(f'{F1=}')\n",
        "\n",
        "print_results(*model6.test('test.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j09ZEA6n7ESV"
      },
      "source": [
        "# BERT:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSpyXoEt7HAC"
      },
      "source": [
        "## Подготовка данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG7_v7I5rZ4d"
      },
      "outputs": [],
      "source": [
        "# Создание обучающей, тестовой и валидационной выборки:\n",
        "train_val, test = train_test_split(df,\n",
        "                                   shuffle=False, test_size=0.2,train_size=0.8)\n",
        "train, val = train_test_split(train_val, test_size = 0.25,train_size =0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-j0dGtshAGb"
      },
      "source": [
        "#### Для упрощения работы используется кастомизированный класс Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDk1mdfGhAPq"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  # Метод, в котором мы инициализируем\n",
        "  # тексты, метки, максимальную дину текста в токенах, а так же токенайзер:\n",
        "  def __init__(self, texts, targets, tokenizer, max_len=512):\n",
        "    self.texts = texts\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  # Метод len возвращает длину нашего датасета:\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  # Метод getitem возвращает словарь,\n",
        "  # который состоит из самого исходного текста,\n",
        "  # списка токенов, маски внимания, а также метки класса.\n",
        "  def __getitem__(self, idx):\n",
        "    text = str(self.texts[idx])\n",
        "    target = self.targets[idx]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "    # Исходный текст нужно обрамлять служебными токенами:\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "    # Дополнять полученные векторы до максимальной длины :\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZF_kD411z39"
      },
      "source": [
        "## Модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_o4PhWFhLRM"
      },
      "outputs": [],
      "source": [
        "class BertClassifier:\n",
        "\n",
        "    # Создание функции инициализации модели:\n",
        "    def __init__(self, model_path, tokenizer_path, n_classes=2, epochs=1, model_save_path='/content/bert.pt'):\n",
        "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model_save_path=model_save_path\n",
        "        self.max_len = 512\n",
        "        self.epochs = epochs\n",
        "        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n",
        "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    # Создание функции инициализации \"хэлперов\"\n",
        "    #(помогают в обучении и оптимизации этого обучения):\n",
        "    def preparation(self, X_train, y_train, X_valid, y_valid):\n",
        "        # Создание datasets:\n",
        "        self.train_set = CustomDataset(X_train, y_train, self.tokenizer)\n",
        "        self.valid_set = CustomDataset(X_valid, y_valid, self.tokenizer)\n",
        "\n",
        "        # Создание data loaders:\n",
        "        self.train_loader = DataLoader(self.train_set, batch_size=2, shuffle=True)\n",
        "        self.valid_loader = DataLoader(self.valid_set, batch_size=2, shuffle=True)\n",
        "\n",
        "        # Инициализация помощников:\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=2e-5, correct_bias=False)\n",
        "        self.scheduler = get_linear_schedule_with_warmup(\n",
        "                self.optimizer,\n",
        "                num_warmup_steps=0,\n",
        "                num_training_steps=len(self.train_loader) * self.epochs\n",
        "            )\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss().to(self.device)\n",
        "\n",
        "    # Создание функции обучения модели в одной эпохе:\n",
        "    def fit(self):\n",
        "        self.model = self.model.train()\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "\n",
        "        # Данные в цикле батчами генерируются с помощью DataLoader:\n",
        "        for data in self.train_loader:\n",
        "            input_ids = data[\"input_ids\"].to(self.device)\n",
        "            attention_mask = data[\"attention_mask\"].to(self.device)\n",
        "            targets = data[\"targets\"].to(self.device)\n",
        "\n",
        "            # Батч подается в модель:\n",
        "            outputs = self.model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "                )\n",
        "\n",
        "            # На выходе получаем распределение вероятности\n",
        "            # по классам и значение ошибки:\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            loss = self.loss_fn(outputs.logits, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Делаем шаг на всех вспомогательных функциях:\n",
        "\n",
        "            # Обратное распространение ошибки:\n",
        "            loss.backward()\n",
        "            # Jбрезаем градиенты для предотвращения \"взрыва\" градиентов:\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            # Шаг оптимизатора:\n",
        "            self.optimizer.step()\n",
        "            # Шаг планировщика:\n",
        "            self.scheduler.step()\n",
        "            # Обнуляем градиенты:\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "        train_acc = correct_predictions.double() / len(self.train_set)\n",
        "        train_loss = np.mean(losses)\n",
        "        return train_acc, train_loss\n",
        "\n",
        "    # Создание функции \"оценки\"(evaluation):\n",
        "    def eval(self):\n",
        "        self.model = self.model.eval()\n",
        "        losses = []\n",
        "        correct_predictions = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in self.valid_loader:\n",
        "                input_ids = data[\"input_ids\"].to(self.device)\n",
        "                attention_mask = data[\"attention_mask\"].to(self.device)\n",
        "                targets = data[\"targets\"].to(self.device)\n",
        "\n",
        "                outputs = self.model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask\n",
        "                    )\n",
        "\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                loss = self.loss_fn(outputs.logits, targets)\n",
        "                correct_predictions += torch.sum(preds == targets)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "        val_acc = correct_predictions.double() / len(self.valid_set)\n",
        "        val_loss = np.mean(losses)\n",
        "        return val_acc, val_loss\n",
        "\n",
        "    #Для обучения на нескольких эпохах используется метод train,\n",
        "    #в котором последовательно вызываются методы fit и eval.\n",
        "    def train(self):\n",
        "        best_accuracy = 0\n",
        "        for epoch in range(self.epochs):\n",
        "            print(f'Epoch {epoch + 1}/{self.epochs}')\n",
        "            train_acc, train_loss = self.fit()\n",
        "            print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "            val_acc, val_loss = self.eval()\n",
        "            print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            if val_acc > best_accuracy:\n",
        "                torch.save(self.model, self.model_save_path)\n",
        "                best_accuracy = val_acc\n",
        "\n",
        "        self.model = torch.load(self.model_save_path)\n",
        "\n",
        "    # Для предсказания класса для нового текста используется метод predict\n",
        "    # Метод работает следующим образом:\n",
        "    # 1 - Токенизируется входной текст;\n",
        "    # 2 - Токенизированный текст подается в модель;\n",
        "    # 3 - На выходе получаем вероятности классов;\n",
        "    # 4 - Возвращаем метку наиболее вероятного класса.\n",
        "    def predict(self, text):\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        out = {\n",
        "              'text': text,\n",
        "              'input_ids': encoding['input_ids'].flatten(),\n",
        "              'attention_mask': encoding['attention_mask'].flatten()\n",
        "          }\n",
        "\n",
        "        input_ids = out[\"input_ids\"].to(self.device)\n",
        "        attention_mask = out[\"attention_mask\"].to(self.device)\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids.unsqueeze(0),\n",
        "            attention_mask=attention_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIVSZUuedyUT"
      },
      "source": [
        "### Инициализация модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPghqwJEsgXH",
        "outputId": "0e59957f-3720-426d-d354-e4c1c51c3595"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "classifier = BertClassifier(\n",
        "        model_path='cointegrated/rubert-tiny2',\n",
        "        tokenizer_path='cointegrated/rubert-tiny2',\n",
        "        n_classes=2,\n",
        "        epochs=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfU8lPz73vqn"
      },
      "source": [
        "### Подготовка данных и хэлперов:\n",
        "Для обучения и оценивания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F343XLaquyu",
        "outputId": "0a46852e-d12d-4281-fbfe-10faa21fcd0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "classifier.preparation(\n",
        "        X_train=list(train['text']),\n",
        "        y_train=list(train['toxic']),\n",
        "        X_valid=list(val['text']),\n",
        "        y_valid=list(val['toxic'])\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_OJ0HT6hLJu"
      },
      "source": [
        "### Обучение модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP66E7_cfE1j"
      },
      "outputs": [],
      "source": [
        "classifier.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRN_CEiW4UPh"
      },
      "source": [
        "## Тестирование модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYOxjCe3s2ZL"
      },
      "outputs": [],
      "source": [
        "texts = list(test['text'])\n",
        "toxic = list(test['toxic'])\n",
        "\n",
        "predictions = [classifier.predict(t) for t in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBpQE1Ols8Ad"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1score = precision_recall_fscore_support(toxic, predictions,average='binary')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3O7p3qi4fP2"
      },
      "source": [
        "## Вывод по моделям:\n",
        "### Fasttext:\n",
        "Модель обучилась очень быстро в сравнении с BERT , всего 5 минут. Результат также положительный: f1 метрика равна 0.959\n",
        "\n",
        "### BERT:\n",
        "Модель обучается Очень долго в сравнении с Fasttext,\n",
        "Результат : f1 метрика равна 0.816, что меньше чем у fasttext, но требованиям всё же соответсует.\n",
        "\n",
        "#### Заказчику я советую использовать модель Fasttext, ткк она быстрее показала лучше результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdB67-h34a7G"
      },
      "source": [
        "# Вывод по проекту:\n",
        "\n",
        "## В данном проекте были предприняты следующие шаги:\n",
        "\n",
        "### 1.) Полученна и анализирована общая информация о данных.\n",
        "\n",
        "### 2.) Выполнена подготовка данных.\n",
        "\n",
        "### 3.) Созданны классы для наиболее успешной работы с моделью.\n",
        "\n",
        "### 4.) Проведена работа с моделями(обучение, тестирование).\n",
        "\n",
        "### 5.) Сделан Вывод о работе каждой модели."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}